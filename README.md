# SkyLark BI Agent

A production-ready **Business Intelligence AI Agent** that connects to live monday.com boards, computes structured business metrics, and generates executive-level insights using Groq LLM â€” all through a conversational chat interface.

**Live Application**: [https://skylark-bi.vercel.app](https://skylark-bi.vercel.app)  
**Backend API**: [https://skylark-bi.onrender.com](https://skylark-bi.onrender.com)  
**API Documentation**: [https://skylark-bi.onrender.com/docs](https://skylark-bi.onrender.com/docs)

> **âš ï¸ Important Note:** This project uses the **Groq free-tier API** for LLM inference. If you encounter errors (e.g. `429 Too Many Requests` or slow responses), it is due to **Groq API rate limits being exceeded** â€” not a codebase or deployment issue. The code, architecture, and deployment are fully functional. Please wait a moment and retry.

---

## Demo

<details>
<summary>ğŸ“Š Leadership Update</summary>

![Leadership Update](assets/chat-leadership-update.png)
</details>

<details>
<summary>ğŸ’° Pipeline Value</summary>

![Pipeline Value](assets/chat-pipeline-value.png)
</details>

<details>
<summary>ğŸ“ˆ Sector Breakdown</summary>

![Sector Breakdown](assets/chat-sector-breakdown.png)
</details>

<details>
<summary>ğŸ¦ Collection Efficiency</summary>

![Collection Efficiency](assets/chat-collection-efficiency.png)
</details>

ğŸ¬ **[Watch Demo Video](assets/skylark-bi-demo.mp4)**

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Vercel (Frontend)                         â”‚
â”‚         React + Vite Â· Chat UI Â· Markdown Rendering         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTPS (POST /ask)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Render (Backend)                           â”‚
â”‚                    FastAPI Server                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ monday  â”‚â”€â”€â–¶â”‚  Data    â”‚â”€â”€â–¶â”‚  Metrics    â”‚              â”‚
â”‚  â”‚ Client  â”‚   â”‚ Cleaner  â”‚   â”‚  Engine     â”‚              â”‚
â”‚  â”‚(GraphQL)â”‚   â”‚          â”‚   â”‚ (7 metrics) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚       â–²                              â”‚                      â”‚
â”‚  Board Cache                  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  (3 min TTL)                  â”‚  AI Service â”‚              â”‚
â”‚                               â”‚  (Groq LLM) â”‚              â”‚
â”‚                               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                      â”‚                      â”‚
â”‚                              Response Cache                 â”‚
â”‚                              (5 min TTL)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚      monday.com GraphQL     â”‚
          â”‚   Deals Board (346 items)   â”‚
          â”‚   Work Orders (176 items)   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Frontend | React 18 + Vite | Chat interface with markdown, metric cards, suggestion chips |
| Backend | FastAPI (Python 3.11) | Async API server with Pydantic validation |
| LLM | Groq (`llama-3.3-70b-versatile`) | Intent extraction, executive summaries, follow-up suggestions |
| Data Source | monday.com GraphQL API | Live Deals & Work Orders boards |
| Caching | In-memory TTL cache (thread-safe) | Board data (3 min) + response deduplication (5 min) |
| Backend Hosting | Render | Python web service with auto-deploy |
| Frontend Hosting | Vercel | Edge CDN with SPA routing |

---

## Features

- **Natural Language Queries** â€” Ask business questions in plain English
- **7 Business Metrics** â€” Pipeline value, sector breakdown, win/loss ratio, revenue analysis, invoiced vs collected, collection efficiency, pipeline-to-revenue ratio
- **Leadership Updates** â€” Structured executive briefing with key numbers, attention items, wins, and recommended actions
- **Data Quality Awareness** â€” Severity-graded warnings (ğŸ”´ğŸŸ¡ğŸŸ¢) about data coverage issues
- **Smart Follow-ups** â€” AI-generated contextual follow-up questions as clickable chips
- **Intent Clarification** â€” Asks for clarification when queries are ambiguous
- **TTL Caching** â€” Board data cached 3 min, AI responses cached 5 min; labelled `source: cache | live`
- **INR Currency Formatting** â€” All monetary values in â‚¹ Cr / â‚¹ L

---

## Project Structure

```
SkyLark-project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app factory, CORS, lifespan
â”‚   â”‚   â”œâ”€â”€ config.py            # Pydantic settings (env vars)
â”‚   â”‚   â”œâ”€â”€ cache.py             # Thread-safe TTL cache (Redis-swappable)
â”‚   â”‚   â”œâ”€â”€ dependencies.py      # Dependency injection
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py       # Request/response Pydantic models
â”‚   â”‚   â”œâ”€â”€ monday_client/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py        # Async GraphQL client with pagination
â”‚   â”‚   â”‚   â””â”€â”€ queries.py       # GraphQL query templates
â”‚   â”‚   â”œâ”€â”€ data_cleaner/
â”‚   â”‚   â”‚   â””â”€â”€ cleaner.py       # Data normalization & quality warnings
â”‚   â”‚   â”œâ”€â”€ business_logic/
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py       # 7 deterministic metric computations
â”‚   â”‚   â”œâ”€â”€ ai_service/
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py       # Groq LLM integration
â”‚   â”‚   â”‚   â””â”€â”€ prompts.py       # Prompt templates
â”‚   â”‚   â””â”€â”€ routers/
â”‚   â”‚       â””â”€â”€ ask.py           # /ask, /health, /boards/summary, /cache/*
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx              # Root layout
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWindow.jsx   # Message list + scroll management
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatMessage.jsx  # Markdown rendering, metrics, warnings
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInput.jsx    # Input bar + suggestion chips
â”‚   â”‚   â”‚   â””â”€â”€ TypingIndicator.jsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â””â”€â”€ useChat.js       # Chat state management
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â””â”€â”€ api.js           # Backend HTTP client
â”‚   â”œâ”€â”€ vercel.json
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ render.yaml                  # Render blueprint
â”œâ”€â”€ DECISION_LOG.md              # Architecture decisions & trade-offs
â””â”€â”€ .gitignore
```

---

## Setup Instructions

### Prerequisites
- Python 3.11+
- Node.js 18+
- monday.com API key
- Groq API key

### Backend

```bash
cd backend
python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your actual API keys

# Run
uvicorn app.main:app --reload --port 8000
```

### Frontend

```bash
cd frontend
npm install

# Optional: point to a different backend
# Create .env with VITE_API_URL=http://localhost:8000

npm run dev
```

Open [http://localhost:5173](http://localhost:5173) in your browser.

---

## Environment Variables

### Backend (.env)

| Variable | Required | Description |
|----------|----------|-------------|
| `MONDAY_API_KEY` | Yes | monday.com API token |
| `DEALS_BOARD_ID` | Yes | Board ID for Deals |
| `WORK_ORDERS_BOARD_ID` | Yes | Board ID for Work Orders |
| `GROQ_API_KEY` | Yes | Groq API key |
| `GROQ_MODEL` | No | Model name (default: `llama-3.3-70b-versatile`) |
| `ALLOWED_ORIGINS` | No | Comma-separated CORS origins for production |
| `CACHE_BOARD_TTL` | No | Board cache TTL in seconds (default: 180) |
| `CACHE_RESPONSE_TTL` | No | Response cache TTL in seconds (default: 300) |

### Frontend (.env)

| Variable | Required | Description |
|----------|----------|-------------|
| `VITE_API_URL` | No | Backend URL (default: `https://skylark-bi.onrender.com`) |

---

## Deployment

### Backend â†’ Render

1. Create a **Web Service** on [render.com](https://render.com)
2. Connect the GitHub repo `abhimh33/Skylark-BI`
3. Settings:
   - **Root Directory**: `backend`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`
4. Add environment variables (see table above)
5. Deploy

### Frontend â†’ Vercel

1. Import the repo on [vercel.com](https://vercel.com)
2. Settings:
   - **Framework**: Vite
   - **Root Directory**: `frontend`
3. Add environment variable: `VITE_API_URL` = your Render URL
4. Deploy

---

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/ask` | Submit a natural language question; returns executive insights |
| `GET` | `/health` | Health check |
| `GET` | `/boards/summary` | Board connectivity & summary stats |
| `GET` | `/cache/stats` | Cache hit/miss statistics |
| `DELETE` | `/cache/clear` | Invalidate all cached data |
| `GET` | `/docs` | Interactive Swagger UI |

### POST /ask â€” Example

**Request:**
```json
{
  "question": "Give me a leadership update",
  "include_raw_data": false
}
```

**Response:**
```json
{
  "insights": "## ğŸ“Š Key Numbers\n\nTotal pipeline: â‚¹2,847 Cr across 346 deals...",
  "key_metrics": [...],
  "data_quality_warnings": [...],
  "intent": { "metric_type": "LEADERSHIP_UPDATE", "confidence": 1.0 },
  "confidence": 1.0,
  "requires_clarification": false,
  "suggested_questions": [
    "What is our collection efficiency?",
    "Break down pipeline by sector",
    "Which deals are stalled?"
  ],
  "source": "live",
  "processing_time_ms": 10691
}
```

---

## Caching Strategy

| Cache | TTL | Purpose |
|-------|-----|---------|
| **Board Cache** | 3 minutes | Avoids repeated monday.com API calls for identical board data |
| **Response Cache** | 5 minutes | Deduplicates identical questions (SHA-256 key of normalised query) |

- Thread-safe via `threading.Lock`
- Lazy expiry on read + manual `purge_expired()`
- Every response tagged with `"source": "cache"` or `"source": "live"`
- Designed as a drop-in replacement for Redis

---

## Future Improvements

- **Redis cache** for multi-instance scaling
- **Streaming responses** (SSE) for faster perceived latency
- **Interactive dashboard** with charts (Recharts)
- **JWT authentication & RBAC**
- **Webhook-driven cache invalidation** from monday.com
- **Prompt evaluation suite** with golden test set
- **Structured logging + APM** (Sentry, Datadog)

---

## License

Private â€” built for evaluation purposes.
